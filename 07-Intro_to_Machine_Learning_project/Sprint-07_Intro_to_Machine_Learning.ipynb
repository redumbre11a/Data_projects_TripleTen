{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Megaline Phone Plan Recommendation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents <a id='back'></a>\n",
    "\n",
    "* [Introduction](#introduction)\n",
    "* [Data Overview](#data_overview)\n",
    "    * [Initialization](#initialization)\n",
    "    * [Load Data](load_data)\n",
    "* [Prepare the Data](#prepare_data)\n",
    "* [Model](#model)\n",
    "    * [Random Forest](#random_forest)\n",
    "        * [Initial Model](#initial_model_random_forest)\n",
    "        * [Hyperparameters](#hyperparameters_random_forest)\n",
    "    * [Decision Tree](#decision_tree)\n",
    "    * [Logistic Regression](#logistic_regression)\n",
    "    * [Final Model](#final_model)\n",
    "    * [Sanity Check](#sanity_check)\n",
    "* [Conclusion](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction <a id='introduction'></a>\n",
    "\n",
    "Mobile carrier Megaline has found out that many of their subscribers use legacy plans. They want to develop a model that would analyze subscribers' behavior and recommend one of Megaline's newer plans: Smart or Ultra.\n",
    "\n",
    "Using the provided data file on behavior data (`/datasets/users_behavior.csv`) about subscribers who have already switched to the new plans (from the project for the Statistical Data Analysis course), a model will be developed that will pick the right plan. The data preprocessing step was completed in the Statistical Data Analysis Project, thus the shown work will move straight to creating the model.\n",
    "\n",
    "Develop a model with the highest possible accuracy. In this project, the threshold for accuracy is 0.75. Check the accuracy using the test dataset.\n",
    "\n",
    "[Back to Contents](#back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Overview <a id='data_overview'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization <a id='initialization'></a> <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading all the libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data <a id='load_data'></a> <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataframe file and storing it to users_behavior_df\n",
    "users_behavior_df = pd.read_csv('/datasets/users_behavior.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the data <a id='prepare_data'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    }
   ],
   "source": [
    "# Print the general/summary information about the DataFrame\n",
    "users_behavior_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print a sample of the data\n",
    "display(users_behavior_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing on this dataset has already been performed from the Statistical Data Analysis Project, thus further preprocessing is not needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model <a id='model'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest <a id='random_forest'></a> </a> <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Model <a id='initial_model_random_forest'></a> </a> <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7838258164852255\n",
      "Test Accuracy: 0.7869362363919129\n"
     ]
    }
   ],
   "source": [
    "# Split the data into features (X) and the target variable (y), where y is the 'is_ultra' column\n",
    "X = users_behavior_df.drop('is_ultra', axis=1)\n",
    "y = users_behavior_df['is_ultra']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=12345)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=12345)\n",
    "\n",
    "# Model selection and hyperparameter tuning\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Validation set evaluation\n",
    "y_val_pred = model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "\n",
    "# Test set evaluation\n",
    "y_test_pred = model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are provided only the source data, it will be split into three parts. By convention in this scenario, the sizes of the validation set and test are usually equal. In this code, the train_test_split function is used with a test_size of 0.4 for the initial split into training and a combined validation-test set. Then, this combined set is further split into validation and test sets using another test_size of 0.5 each. This results in a final 60-20-20 split for train-validation-test, respectively. The required threshold accuracy of 0.75 is achieved with this ratio.\n",
    "\n",
    "In this example, a RandomForestClassifier, which is typically deemed to have the highest accuracy, is used as the model. To confirm if this is the best model to use for this data, other classifiers and experiments with hyperparameters will be done to find the best model for the dataset.\n",
    "\n",
    "Also for consistency, the random_state will remain the same for all model experimentation to make the pseudorandomness static."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing Hyperparameters <a id='hyperparameters_random_forest'></a> </a> <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7966804979253111\n",
      "Test Accuracy: 0.7867494824016563\n"
     ]
    }
   ],
   "source": [
    "# Split the data into features (X) and the target variable (y), where y is the 'is_ultra' column\n",
    "X = users_behavior_df.drop('is_ultra', axis=1)\n",
    "y = users_behavior_df['is_ultra']\n",
    "\n",
    "# Further split the data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=12345)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=12345)\n",
    "\n",
    "# Model selection and hyperparameter tuning\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=12345)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Validation set evaluation\n",
    "y_val_pred = model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "\n",
    "# Test set evaluation\n",
    "y_test_pred = model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code, the train_test_split function is used with a test_size of 0.3 for the initial split into training and a combined validation-test set. Then, this combined set is further split into validation and test sets using another test_size of 0.5 each. This results in a final 70-15-15 split for train-validation-test, respectively. The required threshold accuracy of 0.75 is still achieved with this ratio, but when comparing validation and test accuracies, typically the test accuracy should be as close as possible to the validation accuracy. This indicates that your model's performance on unseen data (test data) is consistent with its performance on validation data.\n",
    "\n",
    "In this case, the validation accuracy is higher than the test accuracy. There is a noticeable drop in accuracy when moving from validation to test data. While the difference isn't extremely large, it might suggest a potential for overfitting. The model might have learned specific patterns present in the validation set but struggled to generalize them to the test set.\n",
    "\n",
    "Becuase the initial model with a 60-20-20 split had a more consistent performance between validation and test accuracies, that ratio will be used in the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7946058091286307\n",
      "Test Accuracy: 0.7867494824016563\n"
     ]
    }
   ],
   "source": [
    "# Split the data into features (X) and the target variable (y), where y is the 'is_ultra' column\n",
    "X = users_behavior_df.drop('is_ultra', axis=1)\n",
    "y = users_behavior_df['is_ultra']\n",
    "\n",
    "# Further split the data into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=12345)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=12345)\n",
    "\n",
    "# Model selection and hyperparameter tuning\n",
    "model = RandomForestClassifier(n_estimators=500, random_state=12345)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Validation set evaluation\n",
    "y_val_pred = model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "\n",
    "# Test set evaluation\n",
    "y_test_pred = model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only change in the above code from the previous one was n_estimators, changing from 100 to 500. Generally, the quality of the end result is directly propportional to the number of trees, as well as training time. Based on the results, there was no significant change by increasing the n_estimators, thus the lower n_estimator of 100 that was initially used will be kept for decreased training time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree <a id='decision_tree'></a> </a> <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.713841368584759\n",
      "Test Accuracy: 0.7309486780715396\n"
     ]
    }
   ],
   "source": [
    "# Split the data into features (X) and the target variable (y), where y is the 'is_ultra' column\n",
    "X = users_behavior_df.drop('is_ultra', axis=1)\n",
    "y = users_behavior_df['is_ultra']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=12345)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=12345)\n",
    "\n",
    "# Model selection and hyperparameter tuning\n",
    "model = DecisionTreeClassifier(random_state=12345)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Validation set evaluation\n",
    "y_val_pred = model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "\n",
    "# Test set evaluation\n",
    "y_test_pred = model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure, The Random Forest is the best model for this applicaiton, a Decision Tree model was also tested and is shown to not pass the accuracy threshold of 0.75. Further tuning on the Decision Tree will not be done since the Random Forest model already achieved the accuracy threshold and is generally deemed the more accurate model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression <a id='logistic_regression'></a> </a> <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7107309486780715\n",
      "Test Accuracy: 0.6842923794712286\n"
     ]
    }
   ],
   "source": [
    "# Split the data into features (X) and the target variable (y), where y is the 'is_ultra' column\n",
    "X = users_behavior_df.drop('is_ultra', axis=1)\n",
    "y = users_behavior_df['is_ultra']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=12345)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=12345)\n",
    "\n",
    "# Model selection and hyperparameter tuning\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Validation set evaluation\n",
    "y_val_pred = model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "\n",
    "# Test set evaluation\n",
    "y_test_pred = model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To further confirm if the Random Forest is the best model for this applicaiton, a Logistic Regression model was also tested and is also shown to not pass the accuracy threshold of 0.75. Further tuning on the Logistic Regression model will not be done since the Random Forest model already achieved the accuracy threshold and is generally deemed the more accurate model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model <a id='final_model'></a> </a> <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7838258164852255\n",
      "Test Accuracy: 0.7869362363919129\n"
     ]
    }
   ],
   "source": [
    "# Split the data into features (X) and the target variable (y), where y is the 'is_ultra' column\n",
    "X = users_behavior_df.drop('is_ultra', axis=1)\n",
    "y = users_behavior_df['is_ultra']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=12345)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=12345)\n",
    "\n",
    "# Model selection and hyperparameter tuning\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Validation set evaluation\n",
    "y_val_pred = model.predict(X_val)\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "\n",
    "# Test set evaluation\n",
    "y_test_pred = model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After testing different models and hyperparameters, the above code was determined to be the final model used to achiev the highest possible accuracy. \n",
    "\n",
    "The model's validation accuracy is around 0.78, meaning it correctly predicted 78% of the labels (in this case, whether a user has the \"Ultra\" plan or not) in the validation dataset.\n",
    "\n",
    "The model's test accuracy is around 0.79, indicating that it correctly predicted 79% of the labels in the test dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check <a id='sanity_check'></a> </a> <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Predicted Distribution:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    0.782271\n",
       "1    0.217729\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Actual Distribution:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    0.706065\n",
       "1    0.293935\n",
       "Name: is_ultra, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Set:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Predicted Distribution:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    0.741835\n",
       "1    0.258165\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Actual Distribution:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    0.684292\n",
       "1    0.315708\n",
       "Name: is_ultra, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate the predicted class distribution for validation and test sets\n",
    "val_pred_distribution = pd.Series(y_val_pred).value_counts(normalize=True)\n",
    "test_pred_distribution = pd.Series(y_test_pred).value_counts(normalize=True)\n",
    "\n",
    "# Calculate the actual class distribution in the validation and test sets\n",
    "val_actual_distribution = y_val.value_counts(normalize=True)\n",
    "test_actual_distribution = y_test.value_counts(normalize=True)\n",
    "\n",
    "# Compare the predicted distribution to the actual distribution for validation set\n",
    "print(\"Validation Set:\")\n",
    "display(\"Predicted Distribution:\", val_pred_distribution)\n",
    "display(\"Actual Distribution:\", val_actual_distribution)\n",
    "print()\n",
    "\n",
    "# Compare the predicted distribution to the actual distribution for test set\n",
    "print(\"Test Set:\")\n",
    "display(\"Predicted Distribution:\", test_pred_distribution)\n",
    "display(\"Actual Distribution:\", test_actual_distribution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both in the validation and test sets, the predicted class distributions are fairly close to the actual class distributions (78% and 71% respectively for the validation set and 74% and 68% respectively for the test set). The model's predictions are consistent with the underlying data distribution.\n",
    "\n",
    "Both the actual and predicted class distributions indicate a class imbalance. Class 0 is the majority class, while Class 1 is the minority class. The model tends to predict more instances as Class 0 (\"Smart\" plan) than as Class 1 (\"Ultra\" plan). This aligns with the majority class being more prevalent.\n",
    "\n",
    "Because the predicted distributions are similar to the actual distributions, it suggests that the model's predictions make sense in the context of the problem. Overall, these results indicate that the final model is producing predictions that align with the class distribution in the data. This is a good sign, as it suggests that the model is not heavily biased towards predicting one class and is making reasonable predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion <a id='conclusion'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After experimenting with various different models and hyperparameters, the random forest model was chosen as the optimum model for the given data, achieving a validation accuracy of 78% and test accuracy of 79%, meeting the required 75% threshold for the project. To ensure the model makes sense, a sanity check was performed and confirmed the soundness of the chosen model. The sanity check showed similar results in the validation and test sets, with the predicted class distributions being fairly close to the actual class distributions (78% and 71% respectively for the validation set and 74% and 68% respectively for the test set). Thus, the model's predictions are consistent with the underlying data distribution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
